{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuehhsuanhuang/Tensor_Network/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensornetwork package\n",
        "\n",
        "Github website : https://github.com/google/TensorNetwork\n",
        "Supervised learning with Quantum-Inspired Tensor Networks:https://arxiv.org/abs/1605.05775 (577 citations)\n"
      ],
      "metadata": {
        "id": "x4rPHfjSDeIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensornetwork\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc6PJidOUgcJ",
        "outputId": "067581ef-b753-4d44-a489-bced6fb6a2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensornetwork\n",
            "  Downloading tensornetwork-0.4.6-py3-none-any.whl (364 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.3/364.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from tensornetwork) (1.25.2)\n",
            "Requirement already satisfied: graphviz>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from tensornetwork) (0.20.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from tensornetwork) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensornetwork) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from tensornetwork) (1.11.4)\n",
            "Installing collected packages: tensornetwork\n",
            "Successfully installed tensornetwork-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensornetwork as tn\n",
        "\n",
        "# Create the nodes\n",
        "a = tn.Node(np.ones((10,)))\n",
        "b = tn.Node(np.ones((10,)))\n",
        "edge = a[0] ^ b[0] # Equal to tn.connect(a[0], b[0])\n",
        "final_node = tn.contract(edge)\n",
        "print(final_node.tensor) # Should print 10.0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSLrQKDZU9wR",
        "outputId": "14c4d699-e991-4ace-c1d9-6684b4e96dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##print(dir(tn))\n",
        "\n",
        "import inspect\n",
        "# Get all functions\n",
        "functions = inspect.getmembers(tn, inspect.isfunction)\n",
        "print(functions)\n",
        "\n",
        "# Get all classes\n",
        "classes = inspect.getmembers(tn, inspect.isclass)\n",
        "print(classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5RF7f-6EqO_",
        "outputId": "bf74c42a-70dd-434b-e7cd-01139041a0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ZNCharge', <function ZNCharge at 0x7f1bad7b1fc0>), ('abs', <function abs at 0x7f1bad81f6d0>), ('check_connected', <function check_connected at 0x7f1bad81c3a0>), ('check_correct', <function check_correct at 0x7f1bad81c310>), ('conj', <function conj at 0x7f1bad81f130>), ('connect', <function connect at 0x7f1bad80f520>), ('contract', <function contract at 0x7f1bad80f370>), ('contract_between', <function contract_between at 0x7f1bad80f640>), ('contract_copy_node', <function contract_copy_node at 0x7f1bad80f400>), ('contract_parallel', <function contract_parallel at 0x7f1bad80f490>), ('contract_trace_edges', <function contract_trace_edges at 0x7f1bad81c5e0>), ('copy', <function copy at 0x7f1bad80fd90>), ('cos', <function cos at 0x7f1bad81f2e0>), ('diagflat', <function diagflat at 0x7f1bad81f520>), ('diagonal', <function diagonal at 0x7f1bad81f490>), ('disconnect', <function disconnect at 0x7f1bad80f5b0>), ('eigh', <function eigh at 0x7f1bad81e170>), ('einsum', <function einsum at 0x7f1bad81f0a0>), ('exp', <function exp at 0x7f1bad81f370>), ('expm', <function expm at 0x7f1bad81e320>), ('eye', <function eye at 0x7f1bad81da20>), ('finalize', <function finalize at 0x7f1bad81ec20>), ('flatten_all_edges', <function flatten_all_edges at 0x7f1bad80ef80>), ('flatten_edges', <function flatten_edges at 0x7f1bad80ee60>), ('flatten_edges_between', <function flatten_edges_between at 0x7f1bad80eef0>), ('from_topology', <function from_topology at 0x7f1bad890280>), ('get_all_dangling', <function get_all_dangling at 0x7f1bad80ed40>), ('get_all_edges', <function get_all_edges at 0x7f1bad81c4c0>), ('get_all_nodes', <function get_all_nodes at 0x7f1bad81c430>), ('get_all_nondangling', <function get_all_nondangling at 0x7f1bad80ecb0>), ('get_neighbors', <function get_neighbors at 0x7f1bad81c790>), ('get_parallel_edges', <function get_parallel_edges at 0x7f1bad80ec20>), ('get_shared_edges', <function get_shared_edges at 0x7f1bad9fb400>), ('get_subgraph_dangling', <function get_subgraph_dangling at 0x7f1bad81c550>), ('hconj', <function hconj at 0x7f1bad81f1c0>), ('inv', <function inv at 0x7f1bad81e290>), ('jit', <function jit at 0x7f1bad81f910>), ('kron', <function kron at 0x7f1bad81f7f0>), ('load_nodes', <function load_nodes at 0x7f1bad8901f0>), ('log', <function log at 0x7f1bad81f400>), ('ncon', <function ncon at 0x7f1bad81eb90>), ('nodes_from_json', <function nodes_from_json at 0x7f1bad81c940>), ('nodes_to_json', <function nodes_to_json at 0x7f1bad81c8b0>), ('norm', <function norm at 0x7f1bad81e200>), ('ones', <function ones at 0x7f1bad81db40>), ('outer', <function outer at 0x7f1bad81f010>), ('outer_product', <function outer_product at 0x7f1bad80f760>), ('outer_product_final_nodes', <function outer_product_final_nodes at 0x7f1bad80f6d0>), ('pivot', <function pivot at 0x7f1bad81f760>), ('qr', <function qr at 0x7f1bad81e050>), ('randn', <function randn at 0x7f1bad81dcf0>), ('random_uniform', <function random_uniform at 0x7f1bad81de10>), ('reachable', <function reachable at 0x7f1bad81c280>), ('redirect_edge', <function redirect_edge at 0x7f1bad81c9d0>), ('reduced_density', <function reduced_density at 0x7f1bad81c670>), ('remove_node', <function remove_node at 0x7f1bad80feb0>), ('replicate_nodes', <function replicate_nodes at 0x7f1bad80fe20>), ('reshape', <function reshape at 0x7f1bad81ed40>), ('rq', <function rq at 0x7f1bad81e0e0>), ('save_nodes', <function save_nodes at 0x7f1bad86ff40>), ('set_default_backend', <function set_default_backend at 0x7f1bad7feb90>), ('shape', <function shape at 0x7f1bad81eef0>), ('sign', <function sign at 0x7f1bad81f640>), ('sin', <function sin at 0x7f1bad81f250>), ('slice_edge', <function slice_edge at 0x7f1bad80f130>), ('split_edge', <function split_edge at 0x7f1bad80f0a0>), ('split_node', <function split_node at 0x7f1bad80ff40>), ('split_node_full_svd', <function split_node_full_svd at 0x7f1bad81c160>), ('split_node_qr', <function split_node_qr at 0x7f1bad81c040>), ('split_node_rq', <function split_node_rq at 0x7f1bad81c0d0>), ('sqrt', <function sqrt at 0x7f1bad81ef80>), ('svd', <function svd at 0x7f1bad81dfc0>), ('switch_backend', <function switch_backend at 0x7f1bad81c700>), ('take_slice', <function take_slice at 0x7f1bad81ee60>), ('tensordot', <function tensordot at 0x7f1bad81ecb0>), ('to_graphviz', <function to_graphviz at 0x7f1bad81fac0>), ('trace', <function trace at 0x7f1bad81f5b0>), ('transpose', <function transpose at 0x7f1bad81edd0>), ('zeros', <function zeros at 0x7f1bad81dab0>)]\n",
            "[('AbstractBackend', <class 'tensornetwork.backends.abstract_backend.AbstractBackend'>), ('AbstractNode', <class 'tensornetwork.network_components.AbstractNode'>), ('BaseCharge', <class 'tensornetwork.block_sparse.charge.BaseCharge'>), ('BlockSparseTensor', <class 'tensornetwork.block_sparse.blocksparsetensor.BlockSparseTensor'>), ('ChargeArray', <class 'tensornetwork.block_sparse.blocksparsetensor.ChargeArray'>), ('CopyNode', <class 'tensornetwork.network_components.CopyNode'>), ('DefaultBackend', <class 'tensornetwork.backend_contextmanager.DefaultBackend'>), ('Edge', <class 'tensornetwork.network_components.Edge'>), ('FiniteDMRG', <class 'tensornetwork.matrixproductstates.dmrg.FiniteDMRG'>), ('FiniteFreeFermion2D', <class 'tensornetwork.matrixproductstates.mpo.FiniteFreeFermion2D'>), ('FiniteMPO', <class 'tensornetwork.matrixproductstates.mpo.FiniteMPO'>), ('FiniteMPS', <class 'tensornetwork.matrixproductstates.finite_mps.FiniteMPS'>), ('FiniteTFI', <class 'tensornetwork.matrixproductstates.mpo.FiniteTFI'>), ('FiniteXXZ', <class 'tensornetwork.matrixproductstates.mpo.FiniteXXZ'>), ('Index', <class 'tensornetwork.block_sparse.index.Index'>), ('InfiniteMPS', <class 'tensornetwork.matrixproductstates.infinite_mps.InfiniteMPS'>), ('NconBuilder', <class 'tensornetwork.tensor.NconBuilder'>), ('Node', <class 'tensornetwork.network_components.Node'>), ('NodeCollection', <class 'tensornetwork.network_components.NodeCollection'>), ('Tensor', <class 'tensornetwork.tensor.Tensor'>), ('U1Charge', <class 'tensornetwork.block_sparse.charge.U1Charge'>), ('Z2Charge', <class 'tensornetwork.block_sparse.charge.Z2Charge'>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_hadamard(net, edge):\n",
        "  hadamard_op = np.array([[1.0, 1.0], [1.0, -1.0]]) / np.sqrt(2.0)\n",
        "  hadamard_node = net.add_node(hadamard_op)\n",
        "  # Connect the \"qubit edge\" to the operator \"input edge\"\n",
        "  net.connect(edge, hadamard_node[1])\n",
        "  return hadamard_node[0] # This is the \"output edge\"."
      ],
      "metadata": {
        "id": "PLJgBkDbVwyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build the quantum circuit.\n",
        "net = tn.ncon.Ncon()  # Use tn.ncon.Ncon() to create a tensor network\n",
        "qubit = net.add_node(np.array([1.0, 0.0])) # A \"zero state\" qubit.\n",
        "qubit_edge = qubit.get_edge(0) # qubit[0] is equivalent.\n",
        "for i in range(5):\n",
        "  qubit_edge = apply_hadamard(net, qubit_edge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "dhpC0cTFV5-v",
        "outputId": "efa76308-8c8b-445f-ebb2-d3bb4d07f7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'function' object has no attribute 'Ncon'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-936f15ec63df>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build the quantum circuit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNcon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use tn.ncon.Ncon() to create a tensor network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mqubit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# A \"zero state\" qubit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mqubit_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqubit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# qubit[0] is equivalent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'Ncon'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = tn.TensorNetwork()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "17m60vPdKVGT",
        "outputId": "d0500070-d0cf-453d-fb7a-8cf5254ea9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensornetwork' has no attribute 'TensorNetwork'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8a0f157ef866>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensornetwork' has no attribute 'TensorNetwork'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(tn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6quOon0NWXDr",
        "outputId": "7820c7b7-927d-49bc-e3ca-382596ba055a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on package tensornetwork:\n",
            "\n",
            "NAME\n",
            "    tensornetwork\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    backend_contextmanager\n",
            "    backends (package)\n",
            "    block_sparse (package)\n",
            "    component_factory\n",
            "    config\n",
            "    contractors (package)\n",
            "    linalg (package)\n",
            "    matrixproductstates (package)\n",
            "    ncon_interface\n",
            "    network_components\n",
            "    network_operations\n",
            "    ops\n",
            "    tensor\n",
            "    tests (package)\n",
            "    tn_keras (package)\n",
            "    utils\n",
            "    version\n",
            "    visualization (package)\n",
            "\n",
            "VERSION\n",
            "    0.4.6\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.10/dist-packages/tensornetwork/__init__.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEublE1mHqyt",
        "outputId": "a4501116-ed88-4f57-d45c-9a25b0ff6b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TenPy\n",
        "website : https://tenpy.readthedocs.io/en/latest/index.html\n",
        "\n",
        "one arxiv article about this : https://arxiv.org/pdf/1805.00055"
      ],
      "metadata": {
        "id": "HWd3sDSAne3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install physics-tenpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNQpPonPntFF",
        "outputId": "86b114ed-fe60-42f2-b304-6ff20cbb70d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting physics-tenpy\n",
            "  Downloading physics_tenpy-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from physics-tenpy) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from physics-tenpy) (1.11.4)\n",
            "Installing collected packages: physics-tenpy\n",
            "Successfully installed physics-tenpy-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(precision=5, suppress=True, linewidth=100)\n",
        "plt.rcParams['figure.dpi'] = 150"
      ],
      "metadata": {
        "id": "QqGSjIAQredr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tenpy\n",
        "import tenpy.linalg.np_conserved as npc\n",
        "from tenpy.algorithms import dmrg\n",
        "from tenpy.networks.mps import MPS\n",
        "from tenpy.models.tf_ising import TFIChain\n",
        "\n",
        "tenpy.tools.misc.setup_logging(to_stdout=\"INFO\")"
      ],
      "metadata": {
        "id": "z3gMDbCrrh72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L = 100\n",
        "model_params = {\n",
        "    'J': 1. , 'g': 1.,  # critical\n",
        "    'L': L,\n",
        "    'bc_MPS': 'finite',\n",
        "}\n",
        "\n",
        "M = TFIChain(model_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCOnnN63rjx4",
        "outputId": "7f212559-e5a4-4d79-d3fe-d7131c19e51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO    : TFIChain: reading 'bc_MPS'='finite'\n",
            "INFO    : TFIChain: reading 'L'=100\n",
            "INFO    : TFIChain: reading 'J'=1.0\n",
            "INFO    : TFIChain: reading 'g'=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "psi = MPS.from_lat_product_state(M.lat, [['up']])\n",
        "dmrg_params = {\n",
        "    'mixer': None,  # setting this to True helps to escape local minima\n",
        "    'max_E_err': 1.e-10,\n",
        "    'trunc_params': {\n",
        "        'chi_max': 100,\n",
        "        'svd_min': 1.e-10,\n",
        "    },\n",
        "    'verbose': True,\n",
        "    'combine': True\n",
        "}\n",
        "eng = dmrg.TwoSiteDMRGEngine(psi, M, dmrg_params)\n",
        "E, psi = eng.run() # the main work; modifies psi in place"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w1gZr2vrnVE",
        "outputId": "8f92fd64-9748-42c4-b020-44f85de3845e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO    : TwoSiteDMRGEngine: subconfig 'trunc_params'=Config(<2 options>, 'trunc_params')\n",
            "INFO    : TwoSiteDMRGEngine: reading 'combine'=True\n",
            "INFO    : TwoSiteDMRGEngine: reading 'mixer'=None\n",
            "INFO    : Running sweep with optimization\n",
            "INFO    : trunc_params: reading 'chi_max'=100\n",
            "INFO    : trunc_params: reading 'svd_min'=1e-10\n",
            "INFO    : checkpoint after sweep 1\n",
            "energy=-126.9290280127262491, max S=0.3829294433343572, age=100, norm_err=1.2e-01\n",
            "Current memory usage 153.1MB, wall time: 7.3s\n",
            "Delta E = nan, Delta S = 3.7668e-01 (per sweep)\n",
            "max trunc_err = 0.0000e+00, max E_trunc = 1.5632e-13\n",
            "chi: 4\n",
            "================================================================================\n",
            "INFO    : Running sweep with optimization\n",
            "INFO    : checkpoint after sweep 2\n",
            "energy=-126.9618018042761776, max S=0.5530507859489378, age=100, norm_err=7.0e-03\n",
            "Current memory usage 155.7MB, wall time: 4.9s\n",
            "Delta E = -3.2774e-02, Delta S = 1.3418e-01 (per sweep)\n",
            "max trunc_err = 0.0000e+00, max E_trunc = 2.1316e-13\n",
            "chi: 16\n",
            "================================================================================\n",
            "INFO    : TwoSiteDMRGEngine: reading 'max_E_err'=1e-10\n",
            "INFO    : Running sweep with optimization\n",
            "INFO    : checkpoint after sweep 3\n",
            "energy=-126.9618767384882290, max S=0.5837971102789331, age=100, norm_err=1.1e-05\n",
            "Current memory usage 163.4MB, wall time: 8.2s\n",
            "Delta E = -7.4934e-05, Delta S = 1.6909e-02 (per sweep)\n",
            "max trunc_err = 4.0634e-20, max E_trunc = 2.8422e-13\n",
            "chi: 64\n",
            "================================================================================\n",
            "INFO    : Running sweep with optimization\n",
            "INFO    : checkpoint after sweep 4\n",
            "energy=-126.9618767396823245, max S=0.5838739117900120, age=100, norm_err=5.6e-10\n",
            "Current memory usage 171.9MB, wall time: 14.0s\n",
            "Delta E = -1.1941e-09, Delta S = 3.4756e-05 (per sweep)\n",
            "max trunc_err = 1.0350e-18, max E_trunc = 2.8422e-13\n",
            "chi: 89\n",
            "================================================================================\n",
            "INFO    : Running sweep with optimization\n",
            "INFO    : checkpoint after sweep 5\n",
            "energy=-126.9618767396805197, max S=0.5838739119327847, age=100, norm_err=5.6e-13\n",
            "Current memory usage 171.9MB, wall time: 5.1s\n",
            "Delta E = 1.8048e-12, Delta S = 5.3029e-11 (per sweep)\n",
            "max trunc_err = 6.6025e-20, max E_trunc = 2.2737e-13\n",
            "chi: 91\n",
            "================================================================================\n",
            "INFO    : TwoSiteDMRGEngine finished after 5 sweeps, max chi=91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tenpy.networks.mps import MPS\n",
        "from tenpy.models.tf_ising import TFIChain\n",
        "from tenpy.algorithms import tebd\n",
        "M = TFIChain({\"L\": 16, \"J\": 1., \"g\": 1.5, \"bc_MPS\": \"finite\"})\n",
        "psi = MPS.from_product_state(M.lat.mps_sites(), [0]*16, \"finite\")\n",
        "tebd_params = {\"order\": 2, \"delta_tau_list\": [0.1, 0.001, 1.e-5],\n",
        "\"max_error_E\": 1.e-6,\n",
        "\"trunc_params\": {\"chi_max\": 30, \"svd_min\": 1.e-10}}\n",
        "eng = tebd.TEBDEngine(psi, M, tebd_params)\n",
        "eng.run_GS() # imaginary time evolution with TEBD\n",
        "print(\"E =\", sum(psi.expectation_value(M.H_bond[1:])))\n",
        "print(\"final bond dimensions: \", psi.chi)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_GsSOCk00qv",
        "outputId": "a8d8e498-af8b-443a-b823-0b3d5f9a12ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO    : TFIChain: reading 'bc_MPS'='finite'\n",
            "INFO    : TFIChain: reading 'L'=16\n",
            "INFO    : TFIChain: reading 'J'=1.0\n",
            "INFO    : TFIChain: reading 'g'=1.5\n",
            "INFO    : TEBDEngine: subconfig 'trunc_params'=Config(<2 options>, 'trunc_params')\n",
            "INFO    : TEBDEngine: reading 'delta_tau_list'=[0.1, 0.001, 1e-05]\n",
            "INFO    : TEBDEngine: reading 'max_error_E'=1e-06\n",
            "INFO    : TEBDEngine: reading 'order'=2\n",
            "INFO    : delta_tau=1.000000e-01\n",
            "INFO    : Calculate U for {'order': 2, 'delta_t': 0.1, 'type_evo': 'imag', 'E_offset': None, 'tau': -0.1j}\n",
            "WARNING : /usr/local/lib/python3.10/dist-packages/tenpy/tools/params.py:232: UserWarning: unused option ['verbose'] for config TwoSiteDMRGEngine\n",
            "  warnings.warn(msg.format(keys=sorted(unused), name=self.name))\n",
            "\n",
            "INFO    : trunc_params: reading 'chi_max'=30\n",
            "INFO    : trunc_params: reading 'svd_min'=1e-10\n",
            "INFO    : --> step=    10, beta=1.000, max(chi)=11,DeltaE=1.67e-01, E_bond=-1.7670113711, Delta_S=1.5703e-01, max(S)=0.1605870878, time simulated: 4.2s\n",
            "INFO    : --> step=    20, beta=2.000, max(chi)=15,DeltaE=4.72e-05, E_bond=-1.7670585220, Delta_S=4.7481e-03, max(S)=0.1662850953, time simulated: 8.7s\n",
            "INFO    : --> step=    30, beta=3.000, max(chi)=18,DeltaE=2.53e-07, E_bond=-1.7670587746, Delta_S=2.6864e-04, max(S)=0.1666648036, time simulated: 12.4s\n",
            "INFO    : delta_tau=1.000000e-03\n",
            "INFO    : Calculate U for {'order': 2, 'delta_t': 0.001, 'type_evo': 'imag', 'E_offset': None, 'tau': -0.001j}\n",
            "INFO    : --> step=    10, beta=3.010, max(chi)=18,DeltaE=4.02e-03, E_bond=-1.7710813300, Delta_S=-1.2691e-02, max(S)=0.1529890132, time simulated: 15.5s\n",
            "INFO    : --> step=    20, beta=3.020, max(chi)=18,DeltaE=1.40e-07, E_bond=-1.7710814700, Delta_S=2.4500e-05, max(S)=0.1530153500, time simulated: 17.3s\n",
            "INFO    : delta_tau=1.000000e-05\n",
            "INFO    : Calculate U for {'order': 2, 'delta_t': 1e-05, 'type_evo': 'imag', 'E_offset': None, 'tau': -1e-05j}\n",
            "INFO    : --> step=    10, beta=3.020, max(chi)=18,DeltaE=3.77e-05, E_bond=-1.7711191980, Delta_S=-1.2151e-04, max(S)=0.1528843954, time simulated: 18.9s\n",
            "INFO    : --> step=    20, beta=3.020, max(chi)=18,DeltaE=1.42e-09, E_bond=-1.7711191994, Delta_S=2.3821e-07, max(S)=0.1528846515, time simulated: 20.0s\n",
            "E = -26.56678799165022\n",
            "final bond dimensions:  [2, 4, 8, 13, 16, 17, 18, 18, 18, 17, 16, 13, 8, 4, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(tenpy.algorithms.tebd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFr-9E5j3UdH",
        "outputId": "960673eb-6548-4285-b84f-b48a66d54e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on module tenpy.algorithms.tebd in tenpy.algorithms:\n",
            "\n",
            "NAME\n",
            "    tenpy.algorithms.tebd - Time evolving block decimation (TEBD).\n",
            "\n",
            "DESCRIPTION\n",
            "    The TEBD algorithm (proposed in :cite:`vidal2004`) uses a trotter decomposition of the\n",
            "    Hamiltonian to perform a time evolution of an MPS. It works only for nearest-neighbor hamiltonians\n",
            "    (in tenpy given by a :class:`~tenpy.models.model.NearestNeighborModel`),\n",
            "    which can be written as :math:`H = H^{even} + H^{odd}`,  such that :math:`H^{even}` contains the\n",
            "    the terms on even bonds (and similar :math:`H^{odd}` the terms on odd bonds).\n",
            "    In the simplest case, we apply first :math:`U=\\exp(-i*dt*H^{even})`,\n",
            "    then :math:`U=\\exp(-i*dt*H^{odd})` for each time step :math:`dt`.\n",
            "    This is correct up to errors of :math:`O(dt^2)`, but to evolve until a time :math:`T`, we need\n",
            "    :math:`T/dt` steps, so in total it is only correct up to error of :math:`O(T*dt)`.\n",
            "    Similarly, there are higher order schemata (in dt) (for more details see\n",
            "    :meth:`TEBDEngine.update`).\n",
            "    \n",
            "    Remember, that bond `i` is between sites `(i-1, i)`, so for a finite MPS it looks like::\n",
            "    \n",
            "        |     - B0 - B1 - B2 - B3 - B4 - B5 - B6 -\n",
            "        |       |    |    |    |    |    |    |\n",
            "        |       |----|    |----|    |----|    |\n",
            "        |       | U1 |    | U3 |    | U5 |    |\n",
            "        |       |----|    |----|    |----|    |\n",
            "        |       |    |----|    |----|    |----|\n",
            "        |       |    | U2 |    | U4 |    | U6 |\n",
            "        |       |    |----|    |----|    |----|\n",
            "        |                   .\n",
            "        |                   .\n",
            "        |                   .\n",
            "    \n",
            "    After each application of a `Ui`, the MPS needs to be truncated - otherwise the bond dimension\n",
            "    `chi` would grow indefinitely. A bound for the error introduced by the truncation is returned.\n",
            "    \n",
            "    If one chooses imaginary :math:`dt`, the exponential projects\n",
            "    (for sufficiently long 'time' evolution) onto the ground state of the Hamiltonian.\n",
            "    \n",
            "    .. note ::\n",
            "        The application of DMRG is typically much more efficient than imaginary TEBD!\n",
            "        Yet, imaginary TEBD might be useful for cross-checks and testing.\n",
            "\n",
            "CLASSES\n",
            "    tenpy.algorithms.algorithm.TimeDependentHAlgorithm(tenpy.algorithms.algorithm.TimeEvolutionAlgorithm)\n",
            "        TimeDependentTEBD(tenpy.algorithms.algorithm.TimeDependentHAlgorithm, TEBDEngine)\n",
            "    tenpy.algorithms.algorithm.TimeEvolutionAlgorithm(tenpy.algorithms.algorithm.Algorithm)\n",
            "        TEBDEngine\n",
            "            QRBasedTEBDEngine\n",
            "            RandomUnitaryEvolution\n",
            "            TimeDependentTEBD(tenpy.algorithms.algorithm.TimeDependentHAlgorithm, TEBDEngine)\n",
            "    \n",
            "    class QRBasedTEBDEngine(TEBDEngine)\n",
            "     |  QRBasedTEBDEngine(psi, model, options, **kwargs)\n",
            "     |  \n",
            "     |  Version of TEBD that relies on QR decompositions rather than SVD.\n",
            "     |  \n",
            "     |  As introduced in :arxiv:`2212.09782`.\n",
            "     |  \n",
            "     |  .. todo ::\n",
            "     |      To use `use_eig_based_svd == True`, which makes sense on GPU only, we need to implement\n",
            "     |      the `_eig_based_svd` for \"non-square\" matrices.\n",
            "     |      This means that :math:`M^{\\dagger} M` and :math:`M M^{\\dagger}` dont have the same size,\n",
            "     |      and we need to disregard those eigenvectors of the larger one, that have eigenvalue zero,\n",
            "     |      since we dont have corresponding eigenvalues of the smaller one.\n",
            "     |  \n",
            "     |  Options\n",
            "     |  -------\n",
            "     |  .. cfg:config :: QRBasedTEBDEngine\n",
            "     |      :include: TEBDEngine\n",
            "     |  \n",
            "     |      cbe_expand : float\n",
            "     |          Expansion rate. The QR-based decomposition is carried out at an expanded bond dimension\n",
            "     |          ``eta = (1 + cbe_expand) * chi``, where ``chi`` is the bond dimension before the time step.\n",
            "     |          Default is `0.1`.\n",
            "     |      cbe_expand_0 : float\n",
            "     |          Expansion rate at low ``chi``.\n",
            "     |          If given, the expansion rate decreases linearly from ``cbe_expand_0`` at ``chi == 1``\n",
            "     |          to ``cbe_expand`` at ``chi == trunc_params['chi_max']``, then remains constant.\n",
            "     |          If not given, the expansion rate is ``cbe_expand`` at all ``chi``.\n",
            "     |      cbe_min_block_increase : int\n",
            "     |          Minimum bond dimension increase for each block. Default is `1`.\n",
            "     |      use_eig_based_svd : bool\n",
            "     |          Whether the SVD of the bond matrix :math:`\\Xi` should be carried out numerically via\n",
            "     |          the eigensystem. This is faster on GPUs, but less accurate.\n",
            "     |          It makes no sense to do this on CPU. It is currently not supported for update_imag.\n",
            "     |          Default is `False`.\n",
            "     |      compute_err : bool\n",
            "     |          Whether the truncation error should be computed exactly.\n",
            "     |          Compared to SVD-based TEBD, computing the truncation error is significantly more expensive.\n",
            "     |          If `True` (default), the full error is computed.\n",
            "     |          Otherwise, the truncation error is set to NaN.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      QRBasedTEBDEngine\n",
            "     |      TEBDEngine\n",
            "     |      tenpy.algorithms.algorithm.TimeEvolutionAlgorithm\n",
            "     |      tenpy.algorithms.algorithm.Algorithm\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  update_bond(self, i, U_bond)\n",
            "     |      Updates the B matrices on a given bond.\n",
            "     |      \n",
            "     |      Function that updates the B matrices, the bond matrix s between and the\n",
            "     |      bond dimension chi for bond i. The corresponding tensor networks look like this::\n",
            "     |      \n",
            "     |      |           --S--B1--B2--           --B1--B2--\n",
            "     |      |                |   |                |   |\n",
            "     |      |     theta:     U_bond        C:     U_bond\n",
            "     |      |                |   |                |   |\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      i : int\n",
            "     |          Bond index; we update the matrices at sites ``i-1, i``.\n",
            "     |      U_bond : :class:`~tenpy.linalg.np_conserved.Array`\n",
            "     |          The bond operator which we apply to the wave function.\n",
            "     |          We expect labels ``'p0', 'p1', 'p0*', 'p1*'``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced by the truncation\n",
            "     |          during this update step.\n",
            "     |  \n",
            "     |  update_bond_imag(self, i, U_bond)\n",
            "     |      Update a bond with a (possibly non-unitary) `U_bond`.\n",
            "     |      \n",
            "     |      Similar as :meth:`update_bond`; but after the SVD just keep the `A, S, B` canonical form.\n",
            "     |      In that way, one can sweep left or right without using old singular values,\n",
            "     |      thus preserving the canonical form during imaginary time evolution.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      i : int\n",
            "     |          Bond index; we update the matrices at sites ``i-1, i``.\n",
            "     |      U_bond : :class:`~tenpy.linalg.np_conserved.Array`\n",
            "     |          The bond operator which we apply to the wave function.\n",
            "     |          We expect labels ``'p0', 'p1', 'p0*', 'p1*'``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced by the truncation\n",
            "     |          during this update step.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from TEBDEngine:\n",
            "     |  \n",
            "     |  __init__(self, psi, model, options, **kwargs)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  calc_U(self, order, delta_t, type_evo='real', E_offset=None)\n",
            "     |      Calculate ``self.U_bond`` from ``self.model.H_bond``.\n",
            "     |      \n",
            "     |      This function calculates\n",
            "     |      \n",
            "     |      * ``U_bond = exp(-i dt (H_bond-E_offset_bond))`` for ``type_evo='real'``, or\n",
            "     |      * ``U_bond = exp(- dt H_bond)`` for ``type_evo='imag'``.\n",
            "     |      \n",
            "     |      For first order (in `delta_t`), we need just one ``dt=delta_t``.\n",
            "     |      Higher order requires smaller `dt` steps, as given by :meth:`suzuki_trotter_time_steps`.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      order : int\n",
            "     |          Trotter order calculated U_bond. See update for more information.\n",
            "     |      delta_t : float\n",
            "     |          Size of the time-step used in calculating U_bond\n",
            "     |      type_evo : ``'imag' | 'real'``\n",
            "     |          Determines whether we perform real or imaginary time-evolution.\n",
            "     |      E_offset : None | list of float\n",
            "     |          Possible offset added to `H_bond` for real-time evolution.\n",
            "     |  \n",
            "     |  evolve(self, N_steps, dt)\n",
            "     |      Evolve by ``dt * N_steps``.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      N_steps : int\n",
            "     |          The number of steps for which the whole lattice should be updated.\n",
            "     |      dt : float\n",
            "     |          The time step; but really this was already used in :meth:`prepare_evolve`.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation during\n",
            "     |          this sequence of evolution steps.\n",
            "     |  \n",
            "     |  evolve_step(self, U_idx_dt, odd)\n",
            "     |      Updates either even *or* odd bonds in unit cell.\n",
            "     |      \n",
            "     |      Depending on the choice of p, this function updates all even (``E``, odd=False,0)\n",
            "     |      **or** odd (``O``) (odd=True,1) bonds::\n",
            "     |      \n",
            "     |      |     - B0 - B1 - B2 - B3 - B4 - B5 - B6 -\n",
            "     |      |       |    |    |    |    |    |    |\n",
            "     |      |       |    |----|    |----|    |----|\n",
            "     |      |       |    |  E |    |  E |    |  E |\n",
            "     |      |       |    |----|    |----|    |----|\n",
            "     |      |       |----|    |----|    |----|    |\n",
            "     |      |       |  O |    |  O |    |  O |    |\n",
            "     |      |       |----|    |----|    |----|    |\n",
            "     |      \n",
            "     |      Note that finite boundary conditions are taken care of by having ``Us[0] = None``.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      U_idx_dt : int\n",
            "     |          Time step index in ``self._U``,\n",
            "     |          evolve with ``Us[i] = self.U[U_idx_dt][i]`` at bond ``(i-1,i)``.\n",
            "     |      odd : bool/int\n",
            "     |          Indication of whether to update even (``odd=False,0``) or even (``odd=True,1``) sites\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation\n",
            "     |          during this sequence of update steps.\n",
            "     |  \n",
            "     |  prepare_evolve(self, dt)\n",
            "     |      Prepare an evolution step.\n",
            "     |      \n",
            "     |      This method is used to prepare repeated calls of :meth:`evolve` given the :attr:`model`.\n",
            "     |      For example, it may generate approximations of ``U=exp(-i H dt)``.\n",
            "     |      To avoid overhead, it may cache the result depending on parameters/options;\n",
            "     |      but it should always regenerate it if :attr:`force_prepare_evolve` is set.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      dt : float\n",
            "     |          The time step to be used.\n",
            "     |  \n",
            "     |  run_GS(self)\n",
            "     |      TEBD algorithm in imaginary time to find the ground state.\n",
            "     |      \n",
            "     |      .. note ::\n",
            "     |          It is almost always more efficient (and hence advisable) to use DMRG.\n",
            "     |          This algorithms can nonetheless be used quite well as a benchmark and for comparison.\n",
            "     |      \n",
            "     |      .. cfg:configoptions :: TEBDEngine\n",
            "     |      \n",
            "     |          delta_tau_list : list\n",
            "     |              A list of floats: the timesteps to be used.\n",
            "     |              Choosing a large timestep `delta_tau` introduces large (Trotter) errors,\n",
            "     |              but a too small time step requires a lot of steps to reach\n",
            "     |              ``exp(-tau H) --> |psi0><psi0|``.\n",
            "     |              Therefore, we start with fairly large time steps for a quick time evolution until\n",
            "     |              convergence, and then gradually decrease the time step.\n",
            "     |          order : int\n",
            "     |              Order of the Suzuki-Trotter decomposition.\n",
            "     |          N_steps : int\n",
            "     |              Number of steps before measurement can be performed\n",
            "     |  \n",
            "     |  update_imag(self, N_steps, call_canonical_form=True)\n",
            "     |      Perform an update suitable for imaginary time evolution.\n",
            "     |      \n",
            "     |      Instead of the even/odd brick structure used for ordinary TEBD,\n",
            "     |      we 'sweep' from left to right and right to left, similar as DMRG.\n",
            "     |      Thanks to that, we are able to preserve at least the orthonormality\n",
            "     |      of the canoncial form.\n",
            "     |      \n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      N_steps : int\n",
            "     |          The number of steps for which the whole lattice should be updated.\n",
            "     |      call_canonical_from : bool\n",
            "     |          The singular values saved in the MPS are not exactly correct after the update,\n",
            "     |          since the non-unitary update on other bonds can change them.\n",
            "     |          To fix this, we call `psi.canonical_form` at the end.\n",
            "     |          Since this is about as a expensive as a single sweep, we allow to disable it,\n",
            "     |          e.g. during the imaginary evolution looking for ground states where the intermediate\n",
            "     |          results is not so critical.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation during\n",
            "     |          this sequence of update steps.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from TEBDEngine:\n",
            "     |  \n",
            "     |  suzuki_trotter_decomposition(order, N_steps)\n",
            "     |      Returns list of necessary steps for the suzuki trotter decomposition.\n",
            "     |      \n",
            "     |      We split the Hamiltonian as :math:`H = H_{even} + H_{odd} = H[0] + H[1]`.\n",
            "     |      The Suzuki-Trotter decomposition is an approximation\n",
            "     |      :math:`\\exp(t H) \\approx prod_{(j, k) \\in ST} \\exp(d[j] t H[k]) + O(t^{order+1 })`.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      order : ``1, 2, 4, '4_opt'``\n",
            "     |          The desired order of the Suzuki-Trotter decomposition.\n",
            "     |          Order ``1`` approximation is simply :math:`e^A a^B`.\n",
            "     |          Order ``2`` is the \"leapfrog\" `e^{A/2} e^B e^{A/2}`.\n",
            "     |          Order ``4`` is the fourth-order from :cite:`suzuki1991` (also referenced in\n",
            "     |          :cite:`schollwoeck2011`), and ``'4_opt'`` gives the optimized version of Equ. (30a) in\n",
            "     |          :cite:`barthel2020`.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      ST_decomposition : list of (int, int)\n",
            "     |          Indices ``j, k`` of the time-steps ``d = suzuki_trotter_time_step(order)`` and\n",
            "     |          the decomposition of `H`.\n",
            "     |          They are chosen such that a subsequent application of ``exp(d[j] t H[k])`` to a given\n",
            "     |          state ``|psi>`` yields ``(exp(N_steps t H[k]) + O(N_steps t^{order+1}))|psi>``.\n",
            "     |  \n",
            "     |  suzuki_trotter_time_steps(order)\n",
            "     |      Return time steps of U for the Suzuki Trotter decomposition of desired order.\n",
            "     |      \n",
            "     |      See :meth:`suzuki_trotter_decomposition` for details.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      order : int\n",
            "     |          The desired order of the Suzuki-Trotter decomposition.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      time_steps : list of float\n",
            "     |          We need ``U = exp(-i H_{even/odd} delta_t * dt)`` for the `dt` returned in this list.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from TEBDEngine:\n",
            "     |  \n",
            "     |  trunc_err_bonds\n",
            "     |      truncation error introduced on each non-trivial bond.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tenpy.algorithms.algorithm.TimeEvolutionAlgorithm:\n",
            "     |  \n",
            "     |  get_resume_data(self, sequential_simulations=False)\n",
            "     |      Return necessary data to resume a :meth:`run` interrupted at a checkpoint.\n",
            "     |      \n",
            "     |      At a :attr:`checkpoint`, you can save :attr:`psi`, :attr:`model` and :attr:`options`\n",
            "     |      along with the data returned by this function.\n",
            "     |      When the simulation aborts, you can resume it using this saved data with::\n",
            "     |      \n",
            "     |          eng = AlgorithmClass(psi, model, options, resume_data=resume_data)\n",
            "     |          eng.resume_run()\n",
            "     |      \n",
            "     |      An algorithm which doesn't support this should override `resume_run` to raise an Error.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      sequential_simulations : bool\n",
            "     |          If True, return only the data for re-initializing a sequential simulation run,\n",
            "     |          where we \"adiabatically\" follow the evolution of a ground state (for variational\n",
            "     |          algorithms), or do series of quenches (for time evolution algorithms);\n",
            "     |          see :func:`~tenpy.simulations.simulation.run_seq_simulations`.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      resume_data : dict\n",
            "     |          Dictionary with necessary data (apart from copies of `psi`, `model`, `options`)\n",
            "     |          that allows to continue the algorithm run from where we are now.\n",
            "     |          It might contain an explicit copy of `psi`.\n",
            "     |  \n",
            "     |  run(self)\n",
            "     |      Perform a (real-)time evolution of :attr:`psi` by `N_steps` * `dt`.\n",
            "     |      \n",
            "     |      You probably want to call this in a loop along with measurements.\n",
            "     |      The recommended way to do this is via the\n",
            "     |      :class:`~tenpy.simulations.time_evolution.RealTimeEvolution`.\n",
            "     |  \n",
            "     |  run_evolution(self, N_steps, dt)\n",
            "     |      Perform a (real-)time evolution of :attr:`psi` by `N_steps` * `dt`.\n",
            "     |      \n",
            "     |      This is the inner part of :meth:`run` without the logging.\n",
            "     |      For parameters see :cfg:config:`TimeEvolutionAlgorithm`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from tenpy.algorithms.algorithm.TimeEvolutionAlgorithm:\n",
            "     |  \n",
            "     |  time_dependent_H = False\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  estimate_RAM(self, mem_saving_factor=None)\n",
            "     |      Gives an approximate prediction for the required memory usage.\n",
            "     |      \n",
            "     |      This calculation is based on the requested bond dimension,\n",
            "     |      the local Hilbert space dimension, the number of sites, and the boundary conditions.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      mem_saving_factor : float\n",
            "     |          Represents the amount of RAM saved due to conservation laws.\n",
            "     |          By default, it is 'None' and is extracted from the model automatically.\n",
            "     |          However, this is only possible in a few cases and needs to be estimated in most cases.\n",
            "     |          This is due to the fact that it is dependent on the model parameters.\n",
            "     |          If one has a better estimate, one can pass the value directly.\n",
            "     |          This value can be extracted by building the initial state `psi`\n",
            "     |          (usually by performing DMRG) and then calling\n",
            "     |          ``print(psi.get_B(0).sparse_stats())``\n",
            "     |          TeNPy will automatically print the fraction of nonzero entries in the first line,\n",
            "     |          for example, ``6 of 16 entries (=0.375) nonzero``.\n",
            "     |          This fraction corresponds to the `mem_saving_factor`; in our example, it is 0.375.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      usage : float\n",
            "     |          Required RAM in MB.\n",
            "     |      \n",
            "     |      See also\n",
            "     |      --------\n",
            "     |      tenpy.simulations.simulation.estimate_simulation_RAM: global function calling this.\n",
            "     |  \n",
            "     |  resume_run(self)\n",
            "     |      Resume a run that was interrupted.\n",
            "     |      \n",
            "     |      In case we saved an intermediate result at a :class:`checkpoint`, this function\n",
            "     |      allows to resume the :meth:`run` of the algorithm (after re-initialization with the\n",
            "     |      `resume_data`).\n",
            "     |      Since most algorithms just have a while loop with break conditions,\n",
            "     |      the default behavior implemented here is to just call :meth:`run`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  switch_engine(other_engine, *, options=None, **kwargs) from builtins.type\n",
            "     |      Initialize algorithm from another algorithm instance of a different class.\n",
            "     |      \n",
            "     |      You can initialize one engine from another, not too different subclasses.\n",
            "     |      Internally, this function calls :meth:`get_resume_data` to extract data from the\n",
            "     |      `other_engine` and then initializes the new class.\n",
            "     |      \n",
            "     |      Note that it transfers the data **without** making copies in most case; even the options!\n",
            "     |      Thus, when you call `run()` on one of the two algorithm instances, it will modify the\n",
            "     |      state, environment, etc. in the other.\n",
            "     |      We recommend to make the switch as ``engine = OtherSubClass.switch_engine(engine)``\n",
            "     |      directly replacing the reference.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      cls : class\n",
            "     |          Subclass of :class:`Algorithm` to be initialized.\n",
            "     |      other_engine : :class:`Algorithm`\n",
            "     |          The engine from which data should be transferred. Another, but not too different\n",
            "     |          algorithm subclass-class; e.g. you can switch from the\n",
            "     |          :class:`~tenpy.algorithms.dmrg.TwoSiteDMRGEngine` to the\n",
            "     |          :class:`~tenpy.algorithms.dmrg.OneSiteDMRGEngine`.\n",
            "     |      options : None | dict-like\n",
            "     |          If not None, these options are used for the new initialization.\n",
            "     |          If None, take the options from the `other_engine`.\n",
            "     |      **kwargs :\n",
            "     |          Further keyword arguments for class initialization.\n",
            "     |          If not defined, `resume_data` is collected with :meth:`get_resume_data`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "    \n",
            "    class RandomUnitaryEvolution(TEBDEngine)\n",
            "     |  RandomUnitaryEvolution(psi, options, **kwargs)\n",
            "     |  \n",
            "     |  Evolution of an MPS with random two-site unitaries in a TEBD-like fashion.\n",
            "     |  \n",
            "     |  Instead of using a model Hamiltonian, this TEBD engine evolves with random two-site unitaries.\n",
            "     |  These unitaries are drawn according to the Haar measure on unitaries obeying the conservation\n",
            "     |  laws dictated by the conserved charges. If no charge is preserved, this distribution is called\n",
            "     |  circular unitary ensemble (CUE), see :func:`~tenpy.linalg.random_matrix.CUE`.\n",
            "     |  The distribution can be changed through the\n",
            "     |  :cfg:option:`RandomUnitaryEvolution.distribution_function`.\n",
            "     |  \n",
            "     |  On one hand, such an evolution is of interest in recent research (see eg. :arxiv:`1710.09827`).\n",
            "     |  On the other hand, it also comes in handy to \"randomize\" an initial state, e.g. for DMRG.\n",
            "     |  Note that the entanglement grows very quickly, choose the truncation parameters accordingly!\n",
            "     |  \n",
            "     |  Options\n",
            "     |  -------\n",
            "     |  .. cfg:config :: RandomUnitaryEvolution\n",
            "     |      :include: TEBDEngine\n",
            "     |  \n",
            "     |      N_steps : int\n",
            "     |          Number of two-site unitaries to be applied on each bond.\n",
            "     |      trunc_params : dict\n",
            "     |          Truncation parameters as described in :cfg:config:`truncate`\n",
            "     |  \n",
            "     |  Examples\n",
            "     |  --------\n",
            "     |  One can initialize a \"random\" state with total Sz = L//2 as follows:\n",
            "     |  \n",
            "     |  .. doctest :: RandomUnitaryEvolution\n",
            "     |  \n",
            "     |      >>> from tenpy.algorithms.tebd import RandomUnitaryEvolution\n",
            "     |      >>> from tenpy.networks.mps import MPS\n",
            "     |      >>> L = 8\n",
            "     |      >>> spin_half = tenpy.networks.site.SpinHalfSite(conserve='Sz')\n",
            "     |      >>> psi = MPS.from_product_state([spin_half]*L, [\"up\", \"down\"]*(L//2), bc='finite')  # Neel\n",
            "     |      >>> print(psi.chi)\n",
            "     |      [1, 1, 1, 1, 1, 1, 1]\n",
            "     |      >>> options = dict(N_steps=2, trunc_params={'chi_max':10})\n",
            "     |      >>> eng = RandomUnitaryEvolution(psi, options)\n",
            "     |      >>> eng.run()\n",
            "     |      >>> print(psi.chi)\n",
            "     |      [2, 4, 8, 10, 8, 4, 2]\n",
            "     |      >>> psi.canonical_form()  # a good idea if there was a truncation necessary.\n",
            "     |  \n",
            "     |  The \"random\" unitaries preserve the specified charges, e.g. here we have Sz-conservation.\n",
            "     |  If you start in a sector of all up spins, the random unitaries can only apply a phase:\n",
            "     |  \n",
            "     |  .. doctest :: RandomUnitaryEvolution\n",
            "     |  \n",
            "     |      >>> psi2 = MPS.from_product_state([spin_half]*L, [\"up\"]*L, bc='finite')  # all spins up\n",
            "     |      >>> print(psi2.chi)\n",
            "     |      [1, 1, 1, 1, 1, 1, 1]\n",
            "     |      >>> eng2 = RandomUnitaryEvolution(psi2, options)\n",
            "     |      >>> eng2.run()  # random unitaries respect Sz conservation -> we stay in all-up sector\n",
            "     |      >>> print(psi2.chi)  # still a product state, not really random!!!\n",
            "     |      [1, 1, 1, 1, 1, 1, 1]\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      RandomUnitaryEvolution\n",
            "     |      TEBDEngine\n",
            "     |      tenpy.algorithms.algorithm.TimeEvolutionAlgorithm\n",
            "     |      tenpy.algorithms.algorithm.Algorithm\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, psi, options, **kwargs)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  calc_U(self)\n",
            "     |      Draw new random two-site unitaries replacing the usual `U` of TEBD.\n",
            "     |      \n",
            "     |      .. cfg:configoptions :: RandomUnitaryEvolution\n",
            "     |      \n",
            "     |          distribution_func : str | function\n",
            "     |              Function or name for one of the matrix ensembles in\n",
            "     |              :mod:`~tenpy.linalg.random_matrix` which generates unitaries (or a subset of them).\n",
            "     |              To be used as `func` for generating unitaries with\n",
            "     |              :meth:`~tenpy.linalg.np_conserved.Array.from_func_square`, i.e. the `U` still\n",
            "     |              preserves the charge block structure!\n",
            "     |          distribution_func_kwargs : dict\n",
            "     |              Extra keyword arguments for `distribution_func`.\n",
            "     |  \n",
            "     |  evolve(self, N_steps, dt)\n",
            "     |      Apply ``N_steps`` random two-site unitaries to each bond (in even-odd pattern).\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      dt : float\n",
            "     |          Mostly ignored, but used as unit to update :attr:`evolved_time`.\n",
            "     |      N_steps : int\n",
            "     |          The number of steps for which the whole lattice should be updated.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation during\n",
            "     |          this sequence of update steps.\n",
            "     |  \n",
            "     |  prepare_evolve(self, dt)\n",
            "     |      Do nothing, as we call :meth:`calc_U` directly in :meth:`update`.\n",
            "     |  \n",
            "     |  run(self)\n",
            "     |      Time evolution with TEBD and random two-site unitaries (possibly conserving charges).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from TEBDEngine:\n",
            "     |  \n",
            "     |  evolve_step(self, U_idx_dt, odd)\n",
            "     |      Updates either even *or* odd bonds in unit cell.\n",
            "     |      \n",
            "     |      Depending on the choice of p, this function updates all even (``E``, odd=False,0)\n",
            "     |      **or** odd (``O``) (odd=True,1) bonds::\n",
            "     |      \n",
            "     |      |     - B0 - B1 - B2 - B3 - B4 - B5 - B6 -\n",
            "     |      |       |    |    |    |    |    |    |\n",
            "     |      |       |    |----|    |----|    |----|\n",
            "     |      |       |    |  E |    |  E |    |  E |\n",
            "     |      |       |    |----|    |----|    |----|\n",
            "     |      |       |----|    |----|    |----|    |\n",
            "     |      |       |  O |    |  O |    |  O |    |\n",
            "     |      |       |----|    |----|    |----|    |\n",
            "     |      \n",
            "     |      Note that finite boundary conditions are taken care of by having ``Us[0] = None``.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      U_idx_dt : int\n",
            "     |          Time step index in ``self._U``,\n",
            "     |          evolve with ``Us[i] = self.U[U_idx_dt][i]`` at bond ``(i-1,i)``.\n",
            "     |      odd : bool/int\n",
            "     |          Indication of whether to update even (``odd=False,0``) or even (``odd=True,1``) sites\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation\n",
            "     |          during this sequence of update steps.\n",
            "     |  \n",
            "     |  run_GS(self)\n",
            "     |      TEBD algorithm in imaginary time to find the ground state.\n",
            "     |      \n",
            "     |      .. note ::\n",
            "     |          It is almost always more efficient (and hence advisable) to use DMRG.\n",
            "     |          This algorithms can nonetheless be used quite well as a benchmark and for comparison.\n",
            "     |      \n",
            "     |      .. cfg:configoptions :: TEBDEngine\n",
            "     |      \n",
            "     |          delta_tau_list : list\n",
            "     |              A list of floats: the timesteps to be used.\n",
            "     |              Choosing a large timestep `delta_tau` introduces large (Trotter) errors,\n",
            "     |              but a too small time step requires a lot of steps to reach\n",
            "     |              ``exp(-tau H) --> |psi0><psi0|``.\n",
            "     |              Therefore, we start with fairly large time steps for a quick time evolution until\n",
            "     |              convergence, and then gradually decrease the time step.\n",
            "     |          order : int\n",
            "     |              Order of the Suzuki-Trotter decomposition.\n",
            "     |          N_steps : int\n",
            "     |              Number of steps before measurement can be performed\n",
            "     |  \n",
            "     |  update_bond(self, i, U_bond)\n",
            "     |      Updates the B matrices on a given bond.\n",
            "     |      \n",
            "     |      Function that updates the B matrices, the bond matrix s between and the\n",
            "     |      bond dimension chi for bond i. The corresponding tensor networks look like this::\n",
            "     |      \n",
            "     |      |           --S--B1--B2--           --B1--B2--\n",
            "     |      |                |   |                |   |\n",
            "     |      |     theta:     U_bond        C:     U_bond\n",
            "     |      |                |   |                |   |\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      i : int\n",
            "     |          Bond index; we update the matrices at sites ``i-1, i``.\n",
            "     |      U_bond : :class:`~tenpy.linalg.np_conserved.Array`\n",
            "     |          The bond operator which we apply to the wave function.\n",
            "     |          We expect labels ``'p0', 'p1', 'p0*', 'p1*'``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced by the truncation\n",
            "     |          during this update step.\n",
            "     |  \n",
            "     |  update_bond_imag(self, i, U_bond)\n",
            "     |      Update a bond with a (possibly non-unitary) `U_bond`.\n",
            "     |      \n",
            "     |      Similar as :meth:`update_bond`; but after the SVD just keep the `A, S, B` canonical form.\n",
            "     |      In that way, one can sweep left or right without using old singular values,\n",
            "     |      thus preserving the canonical form during imaginary time evolution.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      i : int\n",
            "     |          Bond index; we update the matrices at sites ``i-1, i``.\n",
            "     |      U_bond : :class:`~tenpy.linalg.np_conserved.Array`\n",
            "     |          The bond operator which we apply to the wave function.\n",
            "     |          We expect labels ``'p0', 'p1', 'p0*', 'p1*'``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced by the truncation\n",
            "     |          during this update step.\n",
            "     |  \n",
            "     |  update_imag(self, N_steps, call_canonical_form=True)\n",
            "     |      Perform an update suitable for imaginary time evolution.\n",
            "     |      \n",
            "     |      Instead of the even/odd brick structure used for ordinary TEBD,\n",
            "     |      we 'sweep' from left to right and right to left, similar as DMRG.\n",
            "     |      Thanks to that, we are able to preserve at least the orthonormality\n",
            "     |      of the canoncial form.\n",
            "     |      \n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      N_steps : int\n",
            "     |          The number of steps for which the whole lattice should be updated.\n",
            "     |      call_canonical_from : bool\n",
            "     |          The singular values saved in the MPS are not exactly correct after the update,\n",
            "     |          since the non-unitary update on other bonds can change them.\n",
            "     |          To fix this, we call `psi.canonical_form` at the end.\n",
            "     |          Since this is about as a expensive as a single sweep, we allow to disable it,\n",
            "     |          e.g. during the imaginary evolution looking for ground states where the intermediate\n",
            "     |          results is not so critical.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation during\n",
            "     |          this sequence of update steps.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from TEBDEngine:\n",
            "     |  \n",
            "     |  suzuki_trotter_decomposition(order, N_steps)\n",
            "     |      Returns list of necessary steps for the suzuki trotter decomposition.\n",
            "     |      \n",
            "     |      We split the Hamiltonian as :math:`H = H_{even} + H_{odd} = H[0] + H[1]`.\n",
            "     |      The Suzuki-Trotter decomposition is an approximation\n",
            "     |      :math:`\\exp(t H) \\approx prod_{(j, k) \\in ST} \\exp(d[j] t H[k]) + O(t^{order+1 })`.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      order : ``1, 2, 4, '4_opt'``\n",
            "     |          The desired order of the Suzuki-Trotter decomposition.\n",
            "     |          Order ``1`` approximation is simply :math:`e^A a^B`.\n",
            "     |          Order ``2`` is the \"leapfrog\" `e^{A/2} e^B e^{A/2}`.\n",
            "     |          Order ``4`` is the fourth-order from :cite:`suzuki1991` (also referenced in\n",
            "     |          :cite:`schollwoeck2011`), and ``'4_opt'`` gives the optimized version of Equ. (30a) in\n",
            "     |          :cite:`barthel2020`.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      ST_decomposition : list of (int, int)\n",
            "     |          Indices ``j, k`` of the time-steps ``d = suzuki_trotter_time_step(order)`` and\n",
            "     |          the decomposition of `H`.\n",
            "     |          They are chosen such that a subsequent application of ``exp(d[j] t H[k])`` to a given\n",
            "     |          state ``|psi>`` yields ``(exp(N_steps t H[k]) + O(N_steps t^{order+1}))|psi>``.\n",
            "     |  \n",
            "     |  suzuki_trotter_time_steps(order)\n",
            "     |      Return time steps of U for the Suzuki Trotter decomposition of desired order.\n",
            "     |      \n",
            "     |      See :meth:`suzuki_trotter_decomposition` for details.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      order : int\n",
            "     |          The desired order of the Suzuki-Trotter decomposition.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      time_steps : list of float\n",
            "     |          We need ``U = exp(-i H_{even/odd} delta_t * dt)`` for the `dt` returned in this list.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from TEBDEngine:\n",
            "     |  \n",
            "     |  trunc_err_bonds\n",
            "     |      truncation error introduced on each non-trivial bond.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tenpy.algorithms.algorithm.TimeEvolutionAlgorithm:\n",
            "     |  \n",
            "     |  get_resume_data(self, sequential_simulations=False)\n",
            "     |      Return necessary data to resume a :meth:`run` interrupted at a checkpoint.\n",
            "     |      \n",
            "     |      At a :attr:`checkpoint`, you can save :attr:`psi`, :attr:`model` and :attr:`options`\n",
            "     |      along with the data returned by this function.\n",
            "     |      When the simulation aborts, you can resume it using this saved data with::\n",
            "     |      \n",
            "     |          eng = AlgorithmClass(psi, model, options, resume_data=resume_data)\n",
            "     |          eng.resume_run()\n",
            "     |      \n",
            "     |      An algorithm which doesn't support this should override `resume_run` to raise an Error.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      sequential_simulations : bool\n",
            "     |          If True, return only the data for re-initializing a sequential simulation run,\n",
            "     |          where we \"adiabatically\" follow the evolution of a ground state (for variational\n",
            "     |          algorithms), or do series of quenches (for time evolution algorithms);\n",
            "     |          see :func:`~tenpy.simulations.simulation.run_seq_simulations`.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      resume_data : dict\n",
            "     |          Dictionary with necessary data (apart from copies of `psi`, `model`, `options`)\n",
            "     |          that allows to continue the algorithm run from where we are now.\n",
            "     |          It might contain an explicit copy of `psi`.\n",
            "     |  \n",
            "     |  run_evolution(self, N_steps, dt)\n",
            "     |      Perform a (real-)time evolution of :attr:`psi` by `N_steps` * `dt`.\n",
            "     |      \n",
            "     |      This is the inner part of :meth:`run` without the logging.\n",
            "     |      For parameters see :cfg:config:`TimeEvolutionAlgorithm`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from tenpy.algorithms.algorithm.TimeEvolutionAlgorithm:\n",
            "     |  \n",
            "     |  time_dependent_H = False\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  estimate_RAM(self, mem_saving_factor=None)\n",
            "     |      Gives an approximate prediction for the required memory usage.\n",
            "     |      \n",
            "     |      This calculation is based on the requested bond dimension,\n",
            "     |      the local Hilbert space dimension, the number of sites, and the boundary conditions.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      mem_saving_factor : float\n",
            "     |          Represents the amount of RAM saved due to conservation laws.\n",
            "     |          By default, it is 'None' and is extracted from the model automatically.\n",
            "     |          However, this is only possible in a few cases and needs to be estimated in most cases.\n",
            "     |          This is due to the fact that it is dependent on the model parameters.\n",
            "     |          If one has a better estimate, one can pass the value directly.\n",
            "     |          This value can be extracted by building the initial state `psi`\n",
            "     |          (usually by performing DMRG) and then calling\n",
            "     |          ``print(psi.get_B(0).sparse_stats())``\n",
            "     |          TeNPy will automatically print the fraction of nonzero entries in the first line,\n",
            "     |          for example, ``6 of 16 entries (=0.375) nonzero``.\n",
            "     |          This fraction corresponds to the `mem_saving_factor`; in our example, it is 0.375.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      usage : float\n",
            "     |          Required RAM in MB.\n",
            "     |      \n",
            "     |      See also\n",
            "     |      --------\n",
            "     |      tenpy.simulations.simulation.estimate_simulation_RAM: global function calling this.\n",
            "     |  \n",
            "     |  resume_run(self)\n",
            "     |      Resume a run that was interrupted.\n",
            "     |      \n",
            "     |      In case we saved an intermediate result at a :class:`checkpoint`, this function\n",
            "     |      allows to resume the :meth:`run` of the algorithm (after re-initialization with the\n",
            "     |      `resume_data`).\n",
            "     |      Since most algorithms just have a while loop with break conditions,\n",
            "     |      the default behavior implemented here is to just call :meth:`run`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  switch_engine(other_engine, *, options=None, **kwargs) from builtins.type\n",
            "     |      Initialize algorithm from another algorithm instance of a different class.\n",
            "     |      \n",
            "     |      You can initialize one engine from another, not too different subclasses.\n",
            "     |      Internally, this function calls :meth:`get_resume_data` to extract data from the\n",
            "     |      `other_engine` and then initializes the new class.\n",
            "     |      \n",
            "     |      Note that it transfers the data **without** making copies in most case; even the options!\n",
            "     |      Thus, when you call `run()` on one of the two algorithm instances, it will modify the\n",
            "     |      state, environment, etc. in the other.\n",
            "     |      We recommend to make the switch as ``engine = OtherSubClass.switch_engine(engine)``\n",
            "     |      directly replacing the reference.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      cls : class\n",
            "     |          Subclass of :class:`Algorithm` to be initialized.\n",
            "     |      other_engine : :class:`Algorithm`\n",
            "     |          The engine from which data should be transferred. Another, but not too different\n",
            "     |          algorithm subclass-class; e.g. you can switch from the\n",
            "     |          :class:`~tenpy.algorithms.dmrg.TwoSiteDMRGEngine` to the\n",
            "     |          :class:`~tenpy.algorithms.dmrg.OneSiteDMRGEngine`.\n",
            "     |      options : None | dict-like\n",
            "     |          If not None, these options are used for the new initialization.\n",
            "     |          If None, take the options from the `other_engine`.\n",
            "     |      **kwargs :\n",
            "     |          Further keyword arguments for class initialization.\n",
            "     |          If not defined, `resume_data` is collected with :meth:`get_resume_data`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "    \n",
            "    class TEBDEngine(tenpy.algorithms.algorithm.TimeEvolutionAlgorithm)\n",
            "     |  TEBDEngine(psi, model, options, **kwargs)\n",
            "     |  \n",
            "     |  Time Evolving Block Decimation (TEBD) algorithm.\n",
            "     |  \n",
            "     |  Parameters are the same as for :class:`~tenpy.algorithms.algorithm.Algorithm`.\n",
            "     |  \n",
            "     |  Options\n",
            "     |  -------\n",
            "     |  .. cfg:config :: TEBDEngine\n",
            "     |      :include: TimeEvolutionAlgorithm\n",
            "     |  \n",
            "     |      start_trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          Initial truncation error for :attr:`trunc_err`.\n",
            "     |      order : int\n",
            "     |          Order of the algorithm. The total error for evolution up to a fixed time `t`\n",
            "     |          scales as ``O(t*dt^order)``.\n",
            "     |      E_offset : None | list of float\n",
            "     |          Energy offset to be applied in :meth:`calc_U`, see doc there.\n",
            "     |          Only used for real-time evolution!\n",
            "     |      max_delta_t : float | None\n",
            "     |          Threshold for raising errors on too large time steps. Default ``1.0``.\n",
            "     |          The trotterization in the time evolution operator assumes that the time step is small.\n",
            "     |          We raise an error if it is not.\n",
            "     |          Can be downgraded to a warning by setting this option to ``None``.\n",
            "     |  \n",
            "     |  Attributes\n",
            "     |  ----------\n",
            "     |  trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |      The error of the represented state which is introduced due to the truncation during\n",
            "     |      the sequence of update steps.\n",
            "     |  psi : :class:`~tenpy.networks.mps.MPS`\n",
            "     |      The MPS, time evolved in-place.\n",
            "     |  model : :class:`~tenpy.models.model.NearestNeighborModel`\n",
            "     |      The model defining the Hamiltonian.\n",
            "     |  _U : list of list of :class:`~tenpy.linalg.np_conserved.Array`\n",
            "     |      Exponentiated `H_bond` (bond Hamiltonians), i.e. roughly ``exp(-i H_bond dt_i)``.\n",
            "     |      First list for different `dt_i` as necessary for the chosen `order`,\n",
            "     |      second list for the `L` different bonds.\n",
            "     |  _U_param : dict\n",
            "     |      A dictionary containing the information of the latest created `_U`.\n",
            "     |      We don't recalculate `_U` if those parameters didn't change.\n",
            "     |  _trunc_err_bonds : list of :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |      The *local* truncation error introduced at each bond, ignoring the errors at other bonds.\n",
            "     |      The `i`-th entry is left of site `i`.\n",
            "     |  _update_index : None | (int, int)\n",
            "     |      The indices ``i_dt,i_bond`` of ``U_bond = self._U[i_dt][i_bond]`` during update_step.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      TEBDEngine\n",
            "     |      tenpy.algorithms.algorithm.TimeEvolutionAlgorithm\n",
            "     |      tenpy.algorithms.algorithm.Algorithm\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, psi, model, options, **kwargs)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  calc_U(self, order, delta_t, type_evo='real', E_offset=None)\n",
            "     |      Calculate ``self.U_bond`` from ``self.model.H_bond``.\n",
            "     |      \n",
            "     |      This function calculates\n",
            "     |      \n",
            "     |      * ``U_bond = exp(-i dt (H_bond-E_offset_bond))`` for ``type_evo='real'``, or\n",
            "     |      * ``U_bond = exp(- dt H_bond)`` for ``type_evo='imag'``.\n",
            "     |      \n",
            "     |      For first order (in `delta_t`), we need just one ``dt=delta_t``.\n",
            "     |      Higher order requires smaller `dt` steps, as given by :meth:`suzuki_trotter_time_steps`.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      order : int\n",
            "     |          Trotter order calculated U_bond. See update for more information.\n",
            "     |      delta_t : float\n",
            "     |          Size of the time-step used in calculating U_bond\n",
            "     |      type_evo : ``'imag' | 'real'``\n",
            "     |          Determines whether we perform real or imaginary time-evolution.\n",
            "     |      E_offset : None | list of float\n",
            "     |          Possible offset added to `H_bond` for real-time evolution.\n",
            "     |  \n",
            "     |  evolve(self, N_steps, dt)\n",
            "     |      Evolve by ``dt * N_steps``.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      N_steps : int\n",
            "     |          The number of steps for which the whole lattice should be updated.\n",
            "     |      dt : float\n",
            "     |          The time step; but really this was already used in :meth:`prepare_evolve`.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation during\n",
            "     |          this sequence of evolution steps.\n",
            "     |  \n",
            "     |  evolve_step(self, U_idx_dt, odd)\n",
            "     |      Updates either even *or* odd bonds in unit cell.\n",
            "     |      \n",
            "     |      Depending on the choice of p, this function updates all even (``E``, odd=False,0)\n",
            "     |      **or** odd (``O``) (odd=True,1) bonds::\n",
            "     |      \n",
            "     |      |     - B0 - B1 - B2 - B3 - B4 - B5 - B6 -\n",
            "     |      |       |    |    |    |    |    |    |\n",
            "     |      |       |    |----|    |----|    |----|\n",
            "     |      |       |    |  E |    |  E |    |  E |\n",
            "     |      |       |    |----|    |----|    |----|\n",
            "     |      |       |----|    |----|    |----|    |\n",
            "     |      |       |  O |    |  O |    |  O |    |\n",
            "     |      |       |----|    |----|    |----|    |\n",
            "     |      \n",
            "     |      Note that finite boundary conditions are taken care of by having ``Us[0] = None``.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      U_idx_dt : int\n",
            "     |          Time step index in ``self._U``,\n",
            "     |          evolve with ``Us[i] = self.U[U_idx_dt][i]`` at bond ``(i-1,i)``.\n",
            "     |      odd : bool/int\n",
            "     |          Indication of whether to update even (``odd=False,0``) or even (``odd=True,1``) sites\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation\n",
            "     |          during this sequence of update steps.\n",
            "     |  \n",
            "     |  prepare_evolve(self, dt)\n",
            "     |      Prepare an evolution step.\n",
            "     |      \n",
            "     |      This method is used to prepare repeated calls of :meth:`evolve` given the :attr:`model`.\n",
            "     |      For example, it may generate approximations of ``U=exp(-i H dt)``.\n",
            "     |      To avoid overhead, it may cache the result depending on parameters/options;\n",
            "     |      but it should always regenerate it if :attr:`force_prepare_evolve` is set.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      dt : float\n",
            "     |          The time step to be used.\n",
            "     |  \n",
            "     |  run_GS(self)\n",
            "     |      TEBD algorithm in imaginary time to find the ground state.\n",
            "     |      \n",
            "     |      .. note ::\n",
            "     |          It is almost always more efficient (and hence advisable) to use DMRG.\n",
            "     |          This algorithms can nonetheless be used quite well as a benchmark and for comparison.\n",
            "     |      \n",
            "     |      .. cfg:configoptions :: TEBDEngine\n",
            "     |      \n",
            "     |          delta_tau_list : list\n",
            "     |              A list of floats: the timesteps to be used.\n",
            "     |              Choosing a large timestep `delta_tau` introduces large (Trotter) errors,\n",
            "     |              but a too small time step requires a lot of steps to reach\n",
            "     |              ``exp(-tau H) --> |psi0><psi0|``.\n",
            "     |              Therefore, we start with fairly large time steps for a quick time evolution until\n",
            "     |              convergence, and then gradually decrease the time step.\n",
            "     |          order : int\n",
            "     |              Order of the Suzuki-Trotter decomposition.\n",
            "     |          N_steps : int\n",
            "     |              Number of steps before measurement can be performed\n",
            "     |  \n",
            "     |  update_bond(self, i, U_bond)\n",
            "     |      Updates the B matrices on a given bond.\n",
            "     |      \n",
            "     |      Function that updates the B matrices, the bond matrix s between and the\n",
            "     |      bond dimension chi for bond i. The corresponding tensor networks look like this::\n",
            "     |      \n",
            "     |      |           --S--B1--B2--           --B1--B2--\n",
            "     |      |                |   |                |   |\n",
            "     |      |     theta:     U_bond        C:     U_bond\n",
            "     |      |                |   |                |   |\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      i : int\n",
            "     |          Bond index; we update the matrices at sites ``i-1, i``.\n",
            "     |      U_bond : :class:`~tenpy.linalg.np_conserved.Array`\n",
            "     |          The bond operator which we apply to the wave function.\n",
            "     |          We expect labels ``'p0', 'p1', 'p0*', 'p1*'``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced by the truncation\n",
            "     |          during this update step.\n",
            "     |  \n",
            "     |  update_bond_imag(self, i, U_bond)\n",
            "     |      Update a bond with a (possibly non-unitary) `U_bond`.\n",
            "     |      \n",
            "     |      Similar as :meth:`update_bond`; but after the SVD just keep the `A, S, B` canonical form.\n",
            "     |      In that way, one can sweep left or right without using old singular values,\n",
            "     |      thus preserving the canonical form during imaginary time evolution.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      i : int\n",
            "     |          Bond index; we update the matrices at sites ``i-1, i``.\n",
            "     |      U_bond : :class:`~tenpy.linalg.np_conserved.Array`\n",
            "     |          The bond operator which we apply to the wave function.\n",
            "     |          We expect labels ``'p0', 'p1', 'p0*', 'p1*'``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced by the truncation\n",
            "     |          during this update step.\n",
            "     |  \n",
            "     |  update_imag(self, N_steps, call_canonical_form=True)\n",
            "     |      Perform an update suitable for imaginary time evolution.\n",
            "     |      \n",
            "     |      Instead of the even/odd brick structure used for ordinary TEBD,\n",
            "     |      we 'sweep' from left to right and right to left, similar as DMRG.\n",
            "     |      Thanks to that, we are able to preserve at least the orthonormality\n",
            "     |      of the canoncial form.\n",
            "     |      \n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      N_steps : int\n",
            "     |          The number of steps for which the whole lattice should be updated.\n",
            "     |      call_canonical_from : bool\n",
            "     |          The singular values saved in the MPS are not exactly correct after the update,\n",
            "     |          since the non-unitary update on other bonds can change them.\n",
            "     |          To fix this, we call `psi.canonical_form` at the end.\n",
            "     |          Since this is about as a expensive as a single sweep, we allow to disable it,\n",
            "     |          e.g. during the imaginary evolution looking for ground states where the intermediate\n",
            "     |          results is not so critical.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation during\n",
            "     |          this sequence of update steps.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods defined here:\n",
            "     |  \n",
            "     |  suzuki_trotter_decomposition(order, N_steps)\n",
            "     |      Returns list of necessary steps for the suzuki trotter decomposition.\n",
            "     |      \n",
            "     |      We split the Hamiltonian as :math:`H = H_{even} + H_{odd} = H[0] + H[1]`.\n",
            "     |      The Suzuki-Trotter decomposition is an approximation\n",
            "     |      :math:`\\exp(t H) \\approx prod_{(j, k) \\in ST} \\exp(d[j] t H[k]) + O(t^{order+1 })`.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      order : ``1, 2, 4, '4_opt'``\n",
            "     |          The desired order of the Suzuki-Trotter decomposition.\n",
            "     |          Order ``1`` approximation is simply :math:`e^A a^B`.\n",
            "     |          Order ``2`` is the \"leapfrog\" `e^{A/2} e^B e^{A/2}`.\n",
            "     |          Order ``4`` is the fourth-order from :cite:`suzuki1991` (also referenced in\n",
            "     |          :cite:`schollwoeck2011`), and ``'4_opt'`` gives the optimized version of Equ. (30a) in\n",
            "     |          :cite:`barthel2020`.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      ST_decomposition : list of (int, int)\n",
            "     |          Indices ``j, k`` of the time-steps ``d = suzuki_trotter_time_step(order)`` and\n",
            "     |          the decomposition of `H`.\n",
            "     |          They are chosen such that a subsequent application of ``exp(d[j] t H[k])`` to a given\n",
            "     |          state ``|psi>`` yields ``(exp(N_steps t H[k]) + O(N_steps t^{order+1}))|psi>``.\n",
            "     |  \n",
            "     |  suzuki_trotter_time_steps(order)\n",
            "     |      Return time steps of U for the Suzuki Trotter decomposition of desired order.\n",
            "     |      \n",
            "     |      See :meth:`suzuki_trotter_decomposition` for details.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      order : int\n",
            "     |          The desired order of the Suzuki-Trotter decomposition.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      time_steps : list of float\n",
            "     |          We need ``U = exp(-i H_{even/odd} delta_t * dt)`` for the `dt` returned in this list.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties defined here:\n",
            "     |  \n",
            "     |  trunc_err_bonds\n",
            "     |      truncation error introduced on each non-trivial bond.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tenpy.algorithms.algorithm.TimeEvolutionAlgorithm:\n",
            "     |  \n",
            "     |  get_resume_data(self, sequential_simulations=False)\n",
            "     |      Return necessary data to resume a :meth:`run` interrupted at a checkpoint.\n",
            "     |      \n",
            "     |      At a :attr:`checkpoint`, you can save :attr:`psi`, :attr:`model` and :attr:`options`\n",
            "     |      along with the data returned by this function.\n",
            "     |      When the simulation aborts, you can resume it using this saved data with::\n",
            "     |      \n",
            "     |          eng = AlgorithmClass(psi, model, options, resume_data=resume_data)\n",
            "     |          eng.resume_run()\n",
            "     |      \n",
            "     |      An algorithm which doesn't support this should override `resume_run` to raise an Error.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      sequential_simulations : bool\n",
            "     |          If True, return only the data for re-initializing a sequential simulation run,\n",
            "     |          where we \"adiabatically\" follow the evolution of a ground state (for variational\n",
            "     |          algorithms), or do series of quenches (for time evolution algorithms);\n",
            "     |          see :func:`~tenpy.simulations.simulation.run_seq_simulations`.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      resume_data : dict\n",
            "     |          Dictionary with necessary data (apart from copies of `psi`, `model`, `options`)\n",
            "     |          that allows to continue the algorithm run from where we are now.\n",
            "     |          It might contain an explicit copy of `psi`.\n",
            "     |  \n",
            "     |  run(self)\n",
            "     |      Perform a (real-)time evolution of :attr:`psi` by `N_steps` * `dt`.\n",
            "     |      \n",
            "     |      You probably want to call this in a loop along with measurements.\n",
            "     |      The recommended way to do this is via the\n",
            "     |      :class:`~tenpy.simulations.time_evolution.RealTimeEvolution`.\n",
            "     |  \n",
            "     |  run_evolution(self, N_steps, dt)\n",
            "     |      Perform a (real-)time evolution of :attr:`psi` by `N_steps` * `dt`.\n",
            "     |      \n",
            "     |      This is the inner part of :meth:`run` without the logging.\n",
            "     |      For parameters see :cfg:config:`TimeEvolutionAlgorithm`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from tenpy.algorithms.algorithm.TimeEvolutionAlgorithm:\n",
            "     |  \n",
            "     |  time_dependent_H = False\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  estimate_RAM(self, mem_saving_factor=None)\n",
            "     |      Gives an approximate prediction for the required memory usage.\n",
            "     |      \n",
            "     |      This calculation is based on the requested bond dimension,\n",
            "     |      the local Hilbert space dimension, the number of sites, and the boundary conditions.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      mem_saving_factor : float\n",
            "     |          Represents the amount of RAM saved due to conservation laws.\n",
            "     |          By default, it is 'None' and is extracted from the model automatically.\n",
            "     |          However, this is only possible in a few cases and needs to be estimated in most cases.\n",
            "     |          This is due to the fact that it is dependent on the model parameters.\n",
            "     |          If one has a better estimate, one can pass the value directly.\n",
            "     |          This value can be extracted by building the initial state `psi`\n",
            "     |          (usually by performing DMRG) and then calling\n",
            "     |          ``print(psi.get_B(0).sparse_stats())``\n",
            "     |          TeNPy will automatically print the fraction of nonzero entries in the first line,\n",
            "     |          for example, ``6 of 16 entries (=0.375) nonzero``.\n",
            "     |          This fraction corresponds to the `mem_saving_factor`; in our example, it is 0.375.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      usage : float\n",
            "     |          Required RAM in MB.\n",
            "     |      \n",
            "     |      See also\n",
            "     |      --------\n",
            "     |      tenpy.simulations.simulation.estimate_simulation_RAM: global function calling this.\n",
            "     |  \n",
            "     |  resume_run(self)\n",
            "     |      Resume a run that was interrupted.\n",
            "     |      \n",
            "     |      In case we saved an intermediate result at a :class:`checkpoint`, this function\n",
            "     |      allows to resume the :meth:`run` of the algorithm (after re-initialization with the\n",
            "     |      `resume_data`).\n",
            "     |      Since most algorithms just have a while loop with break conditions,\n",
            "     |      the default behavior implemented here is to just call :meth:`run`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  switch_engine(other_engine, *, options=None, **kwargs) from builtins.type\n",
            "     |      Initialize algorithm from another algorithm instance of a different class.\n",
            "     |      \n",
            "     |      You can initialize one engine from another, not too different subclasses.\n",
            "     |      Internally, this function calls :meth:`get_resume_data` to extract data from the\n",
            "     |      `other_engine` and then initializes the new class.\n",
            "     |      \n",
            "     |      Note that it transfers the data **without** making copies in most case; even the options!\n",
            "     |      Thus, when you call `run()` on one of the two algorithm instances, it will modify the\n",
            "     |      state, environment, etc. in the other.\n",
            "     |      We recommend to make the switch as ``engine = OtherSubClass.switch_engine(engine)``\n",
            "     |      directly replacing the reference.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      cls : class\n",
            "     |          Subclass of :class:`Algorithm` to be initialized.\n",
            "     |      other_engine : :class:`Algorithm`\n",
            "     |          The engine from which data should be transferred. Another, but not too different\n",
            "     |          algorithm subclass-class; e.g. you can switch from the\n",
            "     |          :class:`~tenpy.algorithms.dmrg.TwoSiteDMRGEngine` to the\n",
            "     |          :class:`~tenpy.algorithms.dmrg.OneSiteDMRGEngine`.\n",
            "     |      options : None | dict-like\n",
            "     |          If not None, these options are used for the new initialization.\n",
            "     |          If None, take the options from the `other_engine`.\n",
            "     |      **kwargs :\n",
            "     |          Further keyword arguments for class initialization.\n",
            "     |          If not defined, `resume_data` is collected with :meth:`get_resume_data`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "    \n",
            "    class TimeDependentTEBD(tenpy.algorithms.algorithm.TimeDependentHAlgorithm, TEBDEngine)\n",
            "     |  TimeDependentTEBD(psi, model, options, **kwargs)\n",
            "     |  \n",
            "     |  Variant of :class:`TEBDEngine` that can handle time-dependent Hamiltonians.\n",
            "     |  \n",
            "     |  See details in :class:`~tenpy.algorithms.algorithm.TimeDependentHAlgorithm` as well.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      TimeDependentTEBD\n",
            "     |      tenpy.algorithms.algorithm.TimeDependentHAlgorithm\n",
            "     |      TEBDEngine\n",
            "     |      tenpy.algorithms.algorithm.TimeEvolutionAlgorithm\n",
            "     |      tenpy.algorithms.algorithm.Algorithm\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods inherited from tenpy.algorithms.algorithm.TimeDependentHAlgorithm:\n",
            "     |  \n",
            "     |  __init__(self, psi, model, options, **kwargs)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  reinit_model(self)\n",
            "     |      Re-initialize a new :attr:`model` at current :attr:`evolved_time`.\n",
            "     |      \n",
            "     |      Skips re-initialization if the ``model.options['time']`` is the same as `evolved_time`.\n",
            "     |      The model should read out the option ``'time'`` and initialize the corresponding ``H(t)``.\n",
            "     |  \n",
            "     |  run_evolution(self, N_steps, dt)\n",
            "     |      Run the time evolution for N_steps * dt.\n",
            "     |      \n",
            "     |      Updates the model after each time step `dt` to account for changing H(t).\n",
            "     |      For parameters see :cfg:config:`TimeEvolutionAlgorithm`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from tenpy.algorithms.algorithm.TimeDependentHAlgorithm:\n",
            "     |  \n",
            "     |  time_dependent_H = True\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from TEBDEngine:\n",
            "     |  \n",
            "     |  calc_U(self, order, delta_t, type_evo='real', E_offset=None)\n",
            "     |      Calculate ``self.U_bond`` from ``self.model.H_bond``.\n",
            "     |      \n",
            "     |      This function calculates\n",
            "     |      \n",
            "     |      * ``U_bond = exp(-i dt (H_bond-E_offset_bond))`` for ``type_evo='real'``, or\n",
            "     |      * ``U_bond = exp(- dt H_bond)`` for ``type_evo='imag'``.\n",
            "     |      \n",
            "     |      For first order (in `delta_t`), we need just one ``dt=delta_t``.\n",
            "     |      Higher order requires smaller `dt` steps, as given by :meth:`suzuki_trotter_time_steps`.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      order : int\n",
            "     |          Trotter order calculated U_bond. See update for more information.\n",
            "     |      delta_t : float\n",
            "     |          Size of the time-step used in calculating U_bond\n",
            "     |      type_evo : ``'imag' | 'real'``\n",
            "     |          Determines whether we perform real or imaginary time-evolution.\n",
            "     |      E_offset : None | list of float\n",
            "     |          Possible offset added to `H_bond` for real-time evolution.\n",
            "     |  \n",
            "     |  evolve(self, N_steps, dt)\n",
            "     |      Evolve by ``dt * N_steps``.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      N_steps : int\n",
            "     |          The number of steps for which the whole lattice should be updated.\n",
            "     |      dt : float\n",
            "     |          The time step; but really this was already used in :meth:`prepare_evolve`.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation during\n",
            "     |          this sequence of evolution steps.\n",
            "     |  \n",
            "     |  evolve_step(self, U_idx_dt, odd)\n",
            "     |      Updates either even *or* odd bonds in unit cell.\n",
            "     |      \n",
            "     |      Depending on the choice of p, this function updates all even (``E``, odd=False,0)\n",
            "     |      **or** odd (``O``) (odd=True,1) bonds::\n",
            "     |      \n",
            "     |      |     - B0 - B1 - B2 - B3 - B4 - B5 - B6 -\n",
            "     |      |       |    |    |    |    |    |    |\n",
            "     |      |       |    |----|    |----|    |----|\n",
            "     |      |       |    |  E |    |  E |    |  E |\n",
            "     |      |       |    |----|    |----|    |----|\n",
            "     |      |       |----|    |----|    |----|    |\n",
            "     |      |       |  O |    |  O |    |  O |    |\n",
            "     |      |       |----|    |----|    |----|    |\n",
            "     |      \n",
            "     |      Note that finite boundary conditions are taken care of by having ``Us[0] = None``.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      U_idx_dt : int\n",
            "     |          Time step index in ``self._U``,\n",
            "     |          evolve with ``Us[i] = self.U[U_idx_dt][i]`` at bond ``(i-1,i)``.\n",
            "     |      odd : bool/int\n",
            "     |          Indication of whether to update even (``odd=False,0``) or even (``odd=True,1``) sites\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation\n",
            "     |          during this sequence of update steps.\n",
            "     |  \n",
            "     |  prepare_evolve(self, dt)\n",
            "     |      Prepare an evolution step.\n",
            "     |      \n",
            "     |      This method is used to prepare repeated calls of :meth:`evolve` given the :attr:`model`.\n",
            "     |      For example, it may generate approximations of ``U=exp(-i H dt)``.\n",
            "     |      To avoid overhead, it may cache the result depending on parameters/options;\n",
            "     |      but it should always regenerate it if :attr:`force_prepare_evolve` is set.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      dt : float\n",
            "     |          The time step to be used.\n",
            "     |  \n",
            "     |  run_GS(self)\n",
            "     |      TEBD algorithm in imaginary time to find the ground state.\n",
            "     |      \n",
            "     |      .. note ::\n",
            "     |          It is almost always more efficient (and hence advisable) to use DMRG.\n",
            "     |          This algorithms can nonetheless be used quite well as a benchmark and for comparison.\n",
            "     |      \n",
            "     |      .. cfg:configoptions :: TEBDEngine\n",
            "     |      \n",
            "     |          delta_tau_list : list\n",
            "     |              A list of floats: the timesteps to be used.\n",
            "     |              Choosing a large timestep `delta_tau` introduces large (Trotter) errors,\n",
            "     |              but a too small time step requires a lot of steps to reach\n",
            "     |              ``exp(-tau H) --> |psi0><psi0|``.\n",
            "     |              Therefore, we start with fairly large time steps for a quick time evolution until\n",
            "     |              convergence, and then gradually decrease the time step.\n",
            "     |          order : int\n",
            "     |              Order of the Suzuki-Trotter decomposition.\n",
            "     |          N_steps : int\n",
            "     |              Number of steps before measurement can be performed\n",
            "     |  \n",
            "     |  update_bond(self, i, U_bond)\n",
            "     |      Updates the B matrices on a given bond.\n",
            "     |      \n",
            "     |      Function that updates the B matrices, the bond matrix s between and the\n",
            "     |      bond dimension chi for bond i. The corresponding tensor networks look like this::\n",
            "     |      \n",
            "     |      |           --S--B1--B2--           --B1--B2--\n",
            "     |      |                |   |                |   |\n",
            "     |      |     theta:     U_bond        C:     U_bond\n",
            "     |      |                |   |                |   |\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      i : int\n",
            "     |          Bond index; we update the matrices at sites ``i-1, i``.\n",
            "     |      U_bond : :class:`~tenpy.linalg.np_conserved.Array`\n",
            "     |          The bond operator which we apply to the wave function.\n",
            "     |          We expect labels ``'p0', 'p1', 'p0*', 'p1*'``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced by the truncation\n",
            "     |          during this update step.\n",
            "     |  \n",
            "     |  update_bond_imag(self, i, U_bond)\n",
            "     |      Update a bond with a (possibly non-unitary) `U_bond`.\n",
            "     |      \n",
            "     |      Similar as :meth:`update_bond`; but after the SVD just keep the `A, S, B` canonical form.\n",
            "     |      In that way, one can sweep left or right without using old singular values,\n",
            "     |      thus preserving the canonical form during imaginary time evolution.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      i : int\n",
            "     |          Bond index; we update the matrices at sites ``i-1, i``.\n",
            "     |      U_bond : :class:`~tenpy.linalg.np_conserved.Array`\n",
            "     |          The bond operator which we apply to the wave function.\n",
            "     |          We expect labels ``'p0', 'p1', 'p0*', 'p1*'``.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced by the truncation\n",
            "     |          during this update step.\n",
            "     |  \n",
            "     |  update_imag(self, N_steps, call_canonical_form=True)\n",
            "     |      Perform an update suitable for imaginary time evolution.\n",
            "     |      \n",
            "     |      Instead of the even/odd brick structure used for ordinary TEBD,\n",
            "     |      we 'sweep' from left to right and right to left, similar as DMRG.\n",
            "     |      Thanks to that, we are able to preserve at least the orthonormality\n",
            "     |      of the canoncial form.\n",
            "     |      \n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      N_steps : int\n",
            "     |          The number of steps for which the whole lattice should be updated.\n",
            "     |      call_canonical_from : bool\n",
            "     |          The singular values saved in the MPS are not exactly correct after the update,\n",
            "     |          since the non-unitary update on other bonds can change them.\n",
            "     |          To fix this, we call `psi.canonical_form` at the end.\n",
            "     |          Since this is about as a expensive as a single sweep, we allow to disable it,\n",
            "     |          e.g. during the imaginary evolution looking for ground states where the intermediate\n",
            "     |          results is not so critical.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n",
            "     |          The error of the represented state which is introduced due to the truncation during\n",
            "     |          this sequence of update steps.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from TEBDEngine:\n",
            "     |  \n",
            "     |  suzuki_trotter_decomposition(order, N_steps)\n",
            "     |      Returns list of necessary steps for the suzuki trotter decomposition.\n",
            "     |      \n",
            "     |      We split the Hamiltonian as :math:`H = H_{even} + H_{odd} = H[0] + H[1]`.\n",
            "     |      The Suzuki-Trotter decomposition is an approximation\n",
            "     |      :math:`\\exp(t H) \\approx prod_{(j, k) \\in ST} \\exp(d[j] t H[k]) + O(t^{order+1 })`.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      order : ``1, 2, 4, '4_opt'``\n",
            "     |          The desired order of the Suzuki-Trotter decomposition.\n",
            "     |          Order ``1`` approximation is simply :math:`e^A a^B`.\n",
            "     |          Order ``2`` is the \"leapfrog\" `e^{A/2} e^B e^{A/2}`.\n",
            "     |          Order ``4`` is the fourth-order from :cite:`suzuki1991` (also referenced in\n",
            "     |          :cite:`schollwoeck2011`), and ``'4_opt'`` gives the optimized version of Equ. (30a) in\n",
            "     |          :cite:`barthel2020`.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      ST_decomposition : list of (int, int)\n",
            "     |          Indices ``j, k`` of the time-steps ``d = suzuki_trotter_time_step(order)`` and\n",
            "     |          the decomposition of `H`.\n",
            "     |          They are chosen such that a subsequent application of ``exp(d[j] t H[k])`` to a given\n",
            "     |          state ``|psi>`` yields ``(exp(N_steps t H[k]) + O(N_steps t^{order+1}))|psi>``.\n",
            "     |  \n",
            "     |  suzuki_trotter_time_steps(order)\n",
            "     |      Return time steps of U for the Suzuki Trotter decomposition of desired order.\n",
            "     |      \n",
            "     |      See :meth:`suzuki_trotter_decomposition` for details.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      order : int\n",
            "     |          The desired order of the Suzuki-Trotter decomposition.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      time_steps : list of float\n",
            "     |          We need ``U = exp(-i H_{even/odd} delta_t * dt)`` for the `dt` returned in this list.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from TEBDEngine:\n",
            "     |  \n",
            "     |  trunc_err_bonds\n",
            "     |      truncation error introduced on each non-trivial bond.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tenpy.algorithms.algorithm.TimeEvolutionAlgorithm:\n",
            "     |  \n",
            "     |  get_resume_data(self, sequential_simulations=False)\n",
            "     |      Return necessary data to resume a :meth:`run` interrupted at a checkpoint.\n",
            "     |      \n",
            "     |      At a :attr:`checkpoint`, you can save :attr:`psi`, :attr:`model` and :attr:`options`\n",
            "     |      along with the data returned by this function.\n",
            "     |      When the simulation aborts, you can resume it using this saved data with::\n",
            "     |      \n",
            "     |          eng = AlgorithmClass(psi, model, options, resume_data=resume_data)\n",
            "     |          eng.resume_run()\n",
            "     |      \n",
            "     |      An algorithm which doesn't support this should override `resume_run` to raise an Error.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      sequential_simulations : bool\n",
            "     |          If True, return only the data for re-initializing a sequential simulation run,\n",
            "     |          where we \"adiabatically\" follow the evolution of a ground state (for variational\n",
            "     |          algorithms), or do series of quenches (for time evolution algorithms);\n",
            "     |          see :func:`~tenpy.simulations.simulation.run_seq_simulations`.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      resume_data : dict\n",
            "     |          Dictionary with necessary data (apart from copies of `psi`, `model`, `options`)\n",
            "     |          that allows to continue the algorithm run from where we are now.\n",
            "     |          It might contain an explicit copy of `psi`.\n",
            "     |  \n",
            "     |  run(self)\n",
            "     |      Perform a (real-)time evolution of :attr:`psi` by `N_steps` * `dt`.\n",
            "     |      \n",
            "     |      You probably want to call this in a loop along with measurements.\n",
            "     |      The recommended way to do this is via the\n",
            "     |      :class:`~tenpy.simulations.time_evolution.RealTimeEvolution`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  estimate_RAM(self, mem_saving_factor=None)\n",
            "     |      Gives an approximate prediction for the required memory usage.\n",
            "     |      \n",
            "     |      This calculation is based on the requested bond dimension,\n",
            "     |      the local Hilbert space dimension, the number of sites, and the boundary conditions.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      mem_saving_factor : float\n",
            "     |          Represents the amount of RAM saved due to conservation laws.\n",
            "     |          By default, it is 'None' and is extracted from the model automatically.\n",
            "     |          However, this is only possible in a few cases and needs to be estimated in most cases.\n",
            "     |          This is due to the fact that it is dependent on the model parameters.\n",
            "     |          If one has a better estimate, one can pass the value directly.\n",
            "     |          This value can be extracted by building the initial state `psi`\n",
            "     |          (usually by performing DMRG) and then calling\n",
            "     |          ``print(psi.get_B(0).sparse_stats())``\n",
            "     |          TeNPy will automatically print the fraction of nonzero entries in the first line,\n",
            "     |          for example, ``6 of 16 entries (=0.375) nonzero``.\n",
            "     |          This fraction corresponds to the `mem_saving_factor`; in our example, it is 0.375.\n",
            "     |      \n",
            "     |      Returns\n",
            "     |      -------\n",
            "     |      usage : float\n",
            "     |          Required RAM in MB.\n",
            "     |      \n",
            "     |      See also\n",
            "     |      --------\n",
            "     |      tenpy.simulations.simulation.estimate_simulation_RAM: global function calling this.\n",
            "     |  \n",
            "     |  resume_run(self)\n",
            "     |      Resume a run that was interrupted.\n",
            "     |      \n",
            "     |      In case we saved an intermediate result at a :class:`checkpoint`, this function\n",
            "     |      allows to resume the :meth:`run` of the algorithm (after re-initialization with the\n",
            "     |      `resume_data`).\n",
            "     |      Since most algorithms just have a while loop with break conditions,\n",
            "     |      the default behavior implemented here is to just call :meth:`run`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  switch_engine(other_engine, *, options=None, **kwargs) from builtins.type\n",
            "     |      Initialize algorithm from another algorithm instance of a different class.\n",
            "     |      \n",
            "     |      You can initialize one engine from another, not too different subclasses.\n",
            "     |      Internally, this function calls :meth:`get_resume_data` to extract data from the\n",
            "     |      `other_engine` and then initializes the new class.\n",
            "     |      \n",
            "     |      Note that it transfers the data **without** making copies in most case; even the options!\n",
            "     |      Thus, when you call `run()` on one of the two algorithm instances, it will modify the\n",
            "     |      state, environment, etc. in the other.\n",
            "     |      We recommend to make the switch as ``engine = OtherSubClass.switch_engine(engine)``\n",
            "     |      directly replacing the reference.\n",
            "     |      \n",
            "     |      Parameters\n",
            "     |      ----------\n",
            "     |      cls : class\n",
            "     |          Subclass of :class:`Algorithm` to be initialized.\n",
            "     |      other_engine : :class:`Algorithm`\n",
            "     |          The engine from which data should be transferred. Another, but not too different\n",
            "     |          algorithm subclass-class; e.g. you can switch from the\n",
            "     |          :class:`~tenpy.algorithms.dmrg.TwoSiteDMRGEngine` to the\n",
            "     |          :class:`~tenpy.algorithms.dmrg.OneSiteDMRGEngine`.\n",
            "     |      options : None | dict-like\n",
            "     |          If not None, these options are used for the new initialization.\n",
            "     |          If None, take the options from the `other_engine`.\n",
            "     |      **kwargs :\n",
            "     |          Further keyword arguments for class initialization.\n",
            "     |          If not defined, `resume_data` is collected with :meth:`get_resume_data`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from tenpy.algorithms.algorithm.Algorithm:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "\n",
            "DATA\n",
            "    __all__ = ['TEBDEngine', 'QRBasedTEBDEngine', 'RandomUnitaryEvolution'...\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.10/dist-packages/tenpy/algorithms/tebd.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCLNK9g1MZryWBI6kbshNI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}